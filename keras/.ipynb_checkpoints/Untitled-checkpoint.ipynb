{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "#utilities help us transform our data later\n",
    "from keras.utils import * \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, TensorBoard\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Neural Network: \n",
    "\n",
    "Training a NN using Keras involves following steps: \n",
    "\n",
    "i. **Layers, that are combined in a network (or model)**\n",
    "\n",
    "ii. **Input data and corresponding targets**\n",
    "\n",
    "iii. **Loss function that defines the feedback signal used for learning**\n",
    "\n",
    "iv. **Optimizer, that determines how learning proceeds** \n",
    "\n",
    "\n",
    "## i. Layers in Keras \n",
    "\n",
    "A layer is a data processing module that takes input one or more tensors and that outputs one or more tensors. \n",
    "\n",
    "### Different Layers \n",
    "\n",
    "Different layers are appropriate for different tensor formats and different types of data processing. \n",
    "\n",
    "Like simple vector data, stored in 2D tensors of shape (samples, features) is often processed by **densely connected layers** also called **fully connected or dense layers** (model.fit function always takes data in form of (samples, features) \n",
    "\n",
    "Sequence data stored in 3D tensors of shape (samples, timesteps, features) is typically processed by **recurrent layers** such as an **LSTM** layer.  \n",
    "\n",
    "Image data, stored in 4D tensors, is usually processed by **2D convolution layers(Conv2D)**. ((model.fit function always takes data in form of (samples, width, height, color depth) )\n",
    "\n",
    "## Loss function (Objective function)\n",
    "\n",
    "It is the quantity that will be minimized during training. It represents a measure of success for the task at hand\n",
    "\n",
    "A neural network that has multiple outputs may have multiple loss functions (one per output). But the gradient-descent process must be based on a single scalar loss value; so, for multiloss networks, all losses are combined (via averaging) into a single scalar quantity.\n",
    "\n",
    "Choosing the right loss function for the particular problem is very necessary. However when it comes to common problems such as classification, regression, and sequence prediction, there are simple guidelines that can followed such as: \n",
    "\n",
    "** For two-class classification problem , binary crossentropy loss func. is used** \n",
    "\n",
    "** For multi/many class classification problem, categorical crossentropy loss func. is used**\n",
    "\n",
    "** Mean Squared error for a regression problem ** \n",
    "\n",
    "** Connectionist temporal classification(CTC) for a sequence learning problem** \n",
    "\n",
    "and so on. \n",
    "\n",
    "## Optimizer\n",
    "\n",
    "It determines how the network will be updated based on the loss function. \n",
    "\n",
    "Most **common optimizer function used is \"stochastic gradient descent\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class TrainMnistDataSetDense:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.image_height = 28\n",
    "        self.image_width = 28\n",
    "        self.image_depth = 1\n",
    "    \n",
    "    def preProcess(self, x_train, y_train, x_test, y_test):\n",
    "\n",
    "        x_train = x_train.reshape(x_train.shape[0], 28*28)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 28*28)\n",
    "\n",
    "        # Convert data type and normalise values\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "        x_train /= 255\n",
    "        x_test /= 255 \n",
    "\n",
    "        # Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "\n",
    "        y_train = np_utils.to_categorical(y_train,10)\n",
    "        y_test = np_utils.to_categorical(y_test,10)\n",
    "\n",
    "        return x_train, y_train, x_test, y_test\n",
    "    \n",
    "    \n",
    "    def ModelDense(self, input_shape, num_classes):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, input_shape=(input_shape,)))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Dense(num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        return model\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 54s 894us/step - loss: 0.1870 - acc: 0.9429 - val_loss: 0.0953 - val_acc: 0.9713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2249ace90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainMnist = TrainMnistDataSetDense()\n",
    "(x_train, y_train), (x_test, y_test) =  mnist.load_data()\n",
    "X_train, Y_train, X_test, Y_test = trainMnist.preProcess(x_train, y_train, x_test, y_test)\n",
    "input_shape = 28*28\n",
    "# print \"X traing \", \n",
    "# print \"Y train \", Y_train.shape\n",
    "num_classes = 10\n",
    "nb_epoch = 1\n",
    "batch_size = 32\n",
    "\n",
    "# model = trainMnist.modelCNN(input_shape, num_classes)\n",
    "model = trainMnist.ModelDense(X_train.shape[1], num_classes)\n",
    "\n",
    "model_save_path = 'TrainedModelMnist.hdf5'\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "early_stop = EarlyStopping('val_acc', patience=200, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(model_save_path,\n",
    "                                    'val_acc', verbose=0,\n",
    "                                    save_best_only=True)\n",
    "\n",
    "# tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "model_callbacks = [early_stop, model_checkpoint, csv_logger]\n",
    "\n",
    "\n",
    "# K.get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "model.fit(X_train,Y_train,batch_size,nb_epoch, verbose=1,validation_data=(X_test,Y_test),callbacks = model_callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
