{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn import preprocessing  \n",
    "import matplotlib\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>02e7c8990</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>c</td>\n",
       "      <td>U</td>\n",
       "      <td>Pw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>f37df64af</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>pE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>P</td>\n",
       "      <td>eN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>f9d456e57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>c5361037c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>C</td>\n",
       "      <td>OZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2       nom_3  \\\n",
       "0   0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster      Russia   \n",
       "1   1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl         NaN   \n",
       "2   2    0.0    1.0    0.0     F     N   Red        NaN  Hamster      Canada   \n",
       "3   3    NaN    0.0    0.0     F     N   Red     Circle  Hamster     Finland   \n",
       "4   4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster  Costa Rica   \n",
       "\n",
       "   ...      nom_9 ord_0        ord_1     ord_2 ord_3 ord_4  ord_5  day month  \\\n",
       "0  ...  02e7c8990   3.0  Contributor       Hot     c     U     Pw  6.0   3.0   \n",
       "1  ...  f37df64af   3.0  Grandmaster      Warm     e     X     pE  7.0   7.0   \n",
       "2  ...        NaN   3.0          NaN  Freezing     n     P     eN  5.0   9.0   \n",
       "3  ...  f9d456e57   1.0       Novice  Lava Hot     a     C    NaN  3.0   3.0   \n",
       "4  ...  c5361037c   3.0  Grandmaster      Cold     h     C     OZ  5.0  12.0   \n",
       "\n",
       "  target  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/train.csv\", delimiter=\",\")\n",
    "df.head()\n",
    "\n",
    "# this dataset has different types of categorical variables\n",
    "# * Five binary, Ten nominal, Six ordinal, two cyclic and a target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Red\n",
       "2    Red\n",
       "3    Red\n",
       "Name: nom_0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[0,2,3],\"nom_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Categorical Variables\n",
    "\n",
    "## Nominal Variables\n",
    "\n",
    "Variables that have two or more categories which do not have any kind of order associated with them\n",
    "  E.g If gender is classified into two groups, i.e. male and female, it can be considered as a nominal variable\n",
    "  \n",
    "## Ordinal Variables\n",
    "\n",
    "These variables have \"level\" or categories with a particular order associated with them. E.g An ordinal categorical variable can be a feature with three different levels: low, medium and high. Order is important\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Cyclic Variables\n",
    "\n",
    "These variables have \"cycles\" e.g days in a week, months in a year, time(or hours may be)\n",
    "\n",
    "## Binary Variables\n",
    "\n",
    "In form of `0` and `1`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hot', 'Warm', 'Freezing', 'Lava Hot', 'Cold', 'Boiling Hot', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at `ord_2` feature in the dataset\n",
    "# not that there are \"nan\" values too\n",
    "df[\"ord_2\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mapping ordinal value (text to numbers)\n",
    "\n",
    "This type of encoding of categorical varaibles is known as **Label Encoding**, as we are encoding every category as a numerical label using mapping dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# List mapping values here\n",
    "mapping = {\n",
    "    \"Freezing\" : 0,\n",
    "    \"Warm\" : 1,\n",
    "    \"Cold\" : 2, \n",
    "    \"Boiling Hot\" : 3,\n",
    "    \"Hot\" : 4,\n",
    "    \"Lava Hot\" : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Now convert categorical values present in `ord_2` feature to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    142726\n",
       "1.0    124239\n",
       "2.0     97822\n",
       "3.0     84790\n",
       "4.0     67508\n",
       "5.0     64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"ord_2\"] = df.ord_2.map(mapping)\n",
    "# count values after mapping\n",
    "# note that value_counts is used for counting on series(i.e single column)\n",
    "# by default value counts dropna values (you can avoid that by passing flag as false)\n",
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Alternative (Label Encoding) using Scikit-learn\n",
    "This can be done via scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ord 2 before label encoder\n",
      "0                 Hot\n",
      "1                Warm\n",
      "2            Freezing\n",
      "3            Lava Hot\n",
      "4                Cold\n",
      "             ...     \n",
      "599995       Freezing\n",
      "599996    Boiling Hot\n",
      "599997       Freezing\n",
      "599998           Warm\n",
      "599999    Boiling Hot\n",
      "Name: ord_2, Length: 600000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# read data again (as previous df is overwritten)\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "print(\"ord 2 before label encoder\")\n",
    "print(train_df.loc[:, \"ord_2\"])\n",
    "# fill NaN values (with something else as sklearn dont allow nan values, but this column has nan values)\n",
    "train_df.loc[:, \"ord_2\"] = train_df.ord_2.fillna(\"NONE\")\n",
    "# initialize LabelEncoder\n",
    "label_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "train_df.loc[:, \"ord_2\"] = label_enc.fit_transform(train_df.ord_2.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ============== \n",
      " ord 2 values after sklearn transform \n",
      " ============== \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         3\n",
       "1         6\n",
       "2         2\n",
       "3         4\n",
       "4         1\n",
       "         ..\n",
       "599995    2\n",
       "599996    0\n",
       "599997    2\n",
       "599998    6\n",
       "599999    0\n",
       "Name: ord_2, Length: 600000, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" ============== \")\n",
    "print(\" ord 2 values after sklearn transform \")\n",
    "print(\" ============== \")\n",
    "\n",
    "train_df.loc[:, \"ord_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Furthermore, we can directly use these features (i.e. Label Encoded) in tree-based methods such as Decision trees, Randomforest, Xgboost, GBM, etc as they do not assign weights to each feature unlike other algos. such as Linear Regression(y = w*x + b), SVMs, or NN\n",
    "\n",
    "**However for these kind of models, feature normalization or standarization is needed . In other words binarizing them would be efficient as it is only about 1s and 0s**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "E.g\n",
    "\n",
    " freezing ---> 0 ---> 0 0 0\n",
    " \n",
    " Warm ---> 1 ---> 0 0 1\n",
    " \n",
    " Cold ---> 2 ---> 0 1 0\n",
    " \n",
    " Boiling Hot ---> 2 ---> 0 1 0\n",
    " \n",
    " Hot ---> 2 ---> 0 1 0\n",
    " \n",
    " Lava Hot ---> 2 ---> 0 1 0\n",
    "\n",
    "However, note that we are also increasing overall no. of cols (or features) by splitting each feature into \n",
    "its categorical values.\n",
    "\n",
    "#### Drawback of binarizing them\n",
    "**At one point, storing all them would be very expensive considering bigger datasets**\n",
    "\n",
    "### Solution\n",
    "\n",
    "To solve this, we can use **sparse format (a.k.a compressed sparse format)**. It is nothing but a representation or way of storing data in memory in an efficient way. So, we do not store all the values but only that are important i.e. in this case, 1s rather than 0s. \n",
    "\n",
    "In this way, we reduce the memory consumption substainlly.\n",
    "\n",
    "Note: there are various to represent array in sparse format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Sparse Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spparse example   (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 2)\t1\n",
      "example byts without usin sparse format 72\n",
      "example byts with sparse format  32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# consider following array contains one-hot encoded array \n",
    "# we can easily convert that into sparse format\n",
    "example = np.array([\n",
    "    [0, 0, 1],\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 1]\n",
    "])\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "print(f'spparse example {sparse_example}')\n",
    "print(f'example byts without usin sparse format {example.data.nbytes}')\n",
    "print('example byts with sparse format ', sparse_example.data.nbytes)\n",
    "\n",
    "# Image if we have huge number of rows majority filled with 0s then sparse format would be significantly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Lesson : Thats why we prefer sparse format over dense format(filled with 0s and 1s)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hang On, Might be there is another better way to represent this info (Memory Efficient ;) )\n",
    "\n",
    "Thats called one-hot encoding ;) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spparse example   (0, 4)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 0)\t1\n",
      "example byts without usin sparse format 144\n",
      "example byts with sparse format  24\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "# consider following array contains one-hot encoded array \n",
    "# we can easily convert that into sparse format\n",
    "example = np.array([\n",
    "    [0, 0, 0, 0, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 0]\n",
    "])\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "print(f'spparse example {sparse_example}')\n",
    "print(f'example byts without usin sparse format {example.data.nbytes}')\n",
    "print('example byts with sparse format ', sparse_example.data.nbytes)\n",
    "print(\"#\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that, If we use one-hot encoding then total no. of bytes are lesser as compare to the LabelEncoding, and LabelEncoding with sparse**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets encode features using one_hot_encode function provided by sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ord 2 before label encoder\n",
      "['Hot' 'Warm' 'Freezing' ... 'Freezing' 'Warm' 'Boiling Hot']\n",
      "**********\n",
      "ohe_example: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "ohe_example shape : \n",
      " (600000, 7)\n",
      "Size of sparse array: 33600000\n",
      "**********\n",
      "ohe_example shape : \n",
      " (600000, 7)\n",
      "Size of sparse array: 4800000\n"
     ]
    }
   ],
   "source": [
    "# read data again (as previous df is overwritten)\n",
    "\n",
    "train_df_new = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "print(\"ord 2 before label encoder\")\n",
    "print(train_df_new.ord_2.values)\n",
    "print(\"*\"*10)\n",
    "# fill NaN values (with something else as sklearn dont allow nan values, but this column has nan values)\n",
    "train_df_new.loc[:, \"ord_2\"] = train_df_new.ord_2.fillna(\"NONE\")\n",
    "# initialize LabelEncoder\n",
    "# keep sparse = False to get dense array\n",
    "one_hot_enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "# reshape ord2 column to 2-d array as fit_transform func. xpects that\n",
    "reshaped_example = train_df_new.ord_2.values.reshape(-1, 1)\n",
    "ohe_example = one_hot_enc.fit_transform(reshaped_example)\n",
    "print(f\"ohe_example: \\n {ohe_example}\" )\n",
    "# NONE is also one category\n",
    "print(f\"ohe_example shape : \\n {ohe_example.shape}\")\n",
    "\n",
    "# Now check size of array \n",
    "print(f\"Size of sparse array: {ohe_example.data.nbytes}\")\n",
    "\n",
    "print(\"*\"*10)\n",
    "\n",
    "# Now check the size of sparse array i.e. keep sparse=True\n",
    "one_hot_enc_sparse = preprocessing.OneHotEncoder(sparse=True)\n",
    "\n",
    "# reshape ord2 column to 2-d array as fit_transform func. xpects that\n",
    "reshaped_example = train_df_new.ord_2.values.reshape(-1, 1)\n",
    "ohe_example_sparse = one_hot_enc_sparse.fit_transform(reshaped_example)\n",
    "# NONE is also one category (hense there are 7 categories in total)\n",
    "print(f\"ohe_example shape : \\n {ohe_example_sparse.shape}\")\n",
    "\n",
    "# Now check size of array \n",
    "print(f\"Size of sparse array: {ohe_example_sparse.data.nbytes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Away: \n",
    "Size of **sparse one-hot encoder** is way lesser as compared to the **size of densed one-hot-encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We learned the three different ways to handle categorical values:\n",
    "    \n",
    "    * **Dictionary mapping** (maps different categorical values to numbers starting from 0 to N - 1, where N is the total no. of categories in a given feature)   Note: This is not useful to linear models as they expect to be normalized(a.k.a standarized)\n",
    "    * Binarized Variables (you can also use sparse format to reduced the array size)\n",
    "    * One-hot-encode (this can also be stored in a sparse format, if memory size is really problem)\n",
    "    \n",
    "    \n",
    "Although there are many different methods to handle categorical variables. **One such method is about converting categorical variables to numerical variables** (discussed below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no. of times boiling hot occurs  (84790, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_8</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ord_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Boiling Hot</th>\n",
       "      <td>84790</td>\n",
       "      <td>82324</td>\n",
       "      <td>82219</td>\n",
       "      <td>82209</td>\n",
       "      <td>82266</td>\n",
       "      <td>82285</td>\n",
       "      <td>82265</td>\n",
       "      <td>82241</td>\n",
       "      <td>82244</td>\n",
       "      <td>82229</td>\n",
       "      <td>...</td>\n",
       "      <td>82242</td>\n",
       "      <td>82214</td>\n",
       "      <td>82273</td>\n",
       "      <td>82252</td>\n",
       "      <td>82241</td>\n",
       "      <td>82130</td>\n",
       "      <td>82251</td>\n",
       "      <td>82194</td>\n",
       "      <td>82276</td>\n",
       "      <td>84790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cold</th>\n",
       "      <td>97822</td>\n",
       "      <td>94946</td>\n",
       "      <td>94789</td>\n",
       "      <td>94932</td>\n",
       "      <td>94944</td>\n",
       "      <td>94904</td>\n",
       "      <td>94828</td>\n",
       "      <td>94781</td>\n",
       "      <td>94860</td>\n",
       "      <td>94874</td>\n",
       "      <td>...</td>\n",
       "      <td>94881</td>\n",
       "      <td>94853</td>\n",
       "      <td>94854</td>\n",
       "      <td>94789</td>\n",
       "      <td>94859</td>\n",
       "      <td>94965</td>\n",
       "      <td>94850</td>\n",
       "      <td>94856</td>\n",
       "      <td>94850</td>\n",
       "      <td>97822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freezing</th>\n",
       "      <td>142726</td>\n",
       "      <td>138468</td>\n",
       "      <td>138496</td>\n",
       "      <td>138541</td>\n",
       "      <td>138370</td>\n",
       "      <td>138462</td>\n",
       "      <td>138370</td>\n",
       "      <td>138311</td>\n",
       "      <td>138353</td>\n",
       "      <td>138394</td>\n",
       "      <td>...</td>\n",
       "      <td>138525</td>\n",
       "      <td>138475</td>\n",
       "      <td>138411</td>\n",
       "      <td>138417</td>\n",
       "      <td>138475</td>\n",
       "      <td>138565</td>\n",
       "      <td>138579</td>\n",
       "      <td>138547</td>\n",
       "      <td>138447</td>\n",
       "      <td>142726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hot</th>\n",
       "      <td>67508</td>\n",
       "      <td>65487</td>\n",
       "      <td>65544</td>\n",
       "      <td>65501</td>\n",
       "      <td>65362</td>\n",
       "      <td>65495</td>\n",
       "      <td>65500</td>\n",
       "      <td>65518</td>\n",
       "      <td>65465</td>\n",
       "      <td>65415</td>\n",
       "      <td>...</td>\n",
       "      <td>65526</td>\n",
       "      <td>65513</td>\n",
       "      <td>65380</td>\n",
       "      <td>65469</td>\n",
       "      <td>65472</td>\n",
       "      <td>65537</td>\n",
       "      <td>65558</td>\n",
       "      <td>65415</td>\n",
       "      <td>65479</td>\n",
       "      <td>67508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lava Hot</th>\n",
       "      <td>64840</td>\n",
       "      <td>62820</td>\n",
       "      <td>62888</td>\n",
       "      <td>62894</td>\n",
       "      <td>62952</td>\n",
       "      <td>62892</td>\n",
       "      <td>62838</td>\n",
       "      <td>62864</td>\n",
       "      <td>62895</td>\n",
       "      <td>62919</td>\n",
       "      <td>...</td>\n",
       "      <td>62975</td>\n",
       "      <td>62875</td>\n",
       "      <td>62833</td>\n",
       "      <td>62942</td>\n",
       "      <td>62938</td>\n",
       "      <td>62893</td>\n",
       "      <td>62922</td>\n",
       "      <td>62942</td>\n",
       "      <td>63034</td>\n",
       "      <td>64840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warm</th>\n",
       "      <td>124239</td>\n",
       "      <td>120487</td>\n",
       "      <td>120507</td>\n",
       "      <td>120487</td>\n",
       "      <td>120533</td>\n",
       "      <td>120432</td>\n",
       "      <td>120413</td>\n",
       "      <td>120613</td>\n",
       "      <td>120573</td>\n",
       "      <td>120522</td>\n",
       "      <td>...</td>\n",
       "      <td>120577</td>\n",
       "      <td>120458</td>\n",
       "      <td>120453</td>\n",
       "      <td>120570</td>\n",
       "      <td>120553</td>\n",
       "      <td>120456</td>\n",
       "      <td>120596</td>\n",
       "      <td>120606</td>\n",
       "      <td>120431</td>\n",
       "      <td>124239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   bin_0   bin_1   bin_2   bin_3   bin_4   nom_0   nom_1  \\\n",
       "ord_2                                                                         \n",
       "Boiling Hot   84790   82324   82219   82209   82266   82285   82265   82241   \n",
       "Cold          97822   94946   94789   94932   94944   94904   94828   94781   \n",
       "Freezing     142726  138468  138496  138541  138370  138462  138370  138311   \n",
       "Hot           67508   65487   65544   65501   65362   65495   65500   65518   \n",
       "Lava Hot      64840   62820   62888   62894   62952   62892   62838   62864   \n",
       "Warm         124239  120487  120507  120487  120533  120432  120413  120613   \n",
       "\n",
       "              nom_2   nom_3  ...   nom_8   nom_9   ord_0   ord_1   ord_3  \\\n",
       "ord_2                        ...                                           \n",
       "Boiling Hot   82244   82229  ...   82242   82214   82273   82252   82241   \n",
       "Cold          94860   94874  ...   94881   94853   94854   94789   94859   \n",
       "Freezing     138353  138394  ...  138525  138475  138411  138417  138475   \n",
       "Hot           65465   65415  ...   65526   65513   65380   65469   65472   \n",
       "Lava Hot      62895   62919  ...   62975   62875   62833   62942   62938   \n",
       "Warm         120573  120522  ...  120577  120458  120453  120570  120553   \n",
       "\n",
       "              ord_4   ord_5     day   month  target  \n",
       "ord_2                                                \n",
       "Boiling Hot   82130   82251   82194   82276   84790  \n",
       "Cold          94965   94850   94856   94850   97822  \n",
       "Freezing     138565  138579  138547  138447  142726  \n",
       "Hot           65537   65558   65415   65479   67508  \n",
       "Lava Hot      62893   62922   62942   63034   64840  \n",
       "Warm         120456  120596  120606  120431  124239  \n",
       "\n",
       "[6 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets go back again to the dataframe of ord_2 feature and check how many times category \"Boiling Hot \"\n",
    "# occurs in it\n",
    "\n",
    "df = pd.read_csv(\"../data/train.csv\", delimiter=\",\")\n",
    "print(\"total no. of times boiling hot occurs \", df[df.ord_2 == \"Boiling Hot\"].shape)\n",
    "\n",
    "# to get count of all categories\n",
    "\n",
    "df.groupby([\"ord_2\"]).count()\n",
    "# however you can counting varies for each column this is because it ignores nan values\n",
    "# since here id col. cannot/or  be/is not nan so we can use that to get proper count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "Boiling Hot     84790\n",
       "Cold            97822\n",
       "Freezing       142726\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Warm           124239\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"ord_2\"])[\"id\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now if we just replace `ord_2` column with its count values, we have converted it to a feature  which is kind of numerical now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do this, we can create a new column or replace this column by using the transform function by \n",
    "# using the transform function of pandas along with groupby\n",
    "\n",
    "df[\"count_ord2\"] = df.groupby([\"ord_2\"])[\"id\"].transform(\"count\")\n",
    "# you can replace this count of ord_2 with all the categories features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "      <th>count_ord2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>c</td>\n",
       "      <td>U</td>\n",
       "      <td>Pw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>67508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>pE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>124239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>P</td>\n",
       "      <td>eN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>64840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>C</td>\n",
       "      <td>OZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>97822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>599995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>India</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>GZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>142726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>599996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "      <td>sf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>84790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>599997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>H</td>\n",
       "      <td>MV</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>599998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>Warm</td>\n",
       "      <td>m</td>\n",
       "      <td>X</td>\n",
       "      <td>Ey</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>124239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>599999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>b</td>\n",
       "      <td>O</td>\n",
       "      <td>uI</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>84790.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2  \\\n",
       "0            0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster   \n",
       "1            1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl   \n",
       "2            2    0.0    1.0    0.0     F     N   Red        NaN  Hamster   \n",
       "3            3    NaN    0.0    0.0     F     N   Red     Circle  Hamster   \n",
       "4            4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster   \n",
       "...        ...    ...    ...    ...   ...   ...   ...        ...      ...   \n",
       "599995  599995    0.0    1.0    0.0     T     N   Red    Polygon  Axolotl   \n",
       "599996  599996    1.0    0.0    0.0     T     Y  Blue    Polygon      Dog   \n",
       "599997  599997    0.0    0.0    0.0     F     Y   Red     Circle  Axolotl   \n",
       "599998  599998    1.0    1.0    0.0     F     Y   NaN    Polygon  Axolotl   \n",
       "599999  599999    0.0    0.0    0.0     T     N  Blue   Triangle      Dog   \n",
       "\n",
       "             nom_3  ... ord_0        ord_1        ord_2 ord_3 ord_4 ord_5  \\\n",
       "0           Russia  ...   3.0  Contributor          Hot     c     U    Pw   \n",
       "1              NaN  ...   3.0  Grandmaster         Warm     e     X    pE   \n",
       "2           Canada  ...   3.0          NaN     Freezing     n     P    eN   \n",
       "3          Finland  ...   1.0       Novice     Lava Hot     a     C   NaN   \n",
       "4       Costa Rica  ...   3.0  Grandmaster         Cold     h     C    OZ   \n",
       "...            ...  ...   ...          ...          ...   ...   ...   ...   \n",
       "599995       India  ...   3.0       Novice     Freezing     a     R    GZ   \n",
       "599996  Costa Rica  ...   2.0       Novice  Boiling Hot     n     N    sf   \n",
       "599997      Russia  ...   2.0  Contributor     Freezing     n     H    MV   \n",
       "599998         NaN  ...   1.0       Master         Warm     m     X    Ey   \n",
       "599999      Russia  ...   1.0  Contributor  Boiling Hot     b     O    uI   \n",
       "\n",
       "        day month target count_ord2  \n",
       "0       6.0   3.0      0    67508.0  \n",
       "1       7.0   7.0      0   124239.0  \n",
       "2       5.0   9.0      0   142726.0  \n",
       "3       3.0   3.0      0    64840.0  \n",
       "4       5.0  12.0      0    97822.0  \n",
       "...     ...   ...    ...        ...  \n",
       "599995  5.0   NaN      0   142726.0  \n",
       "599996  NaN   3.0      0    84790.0  \n",
       "599997  7.0   5.0      0   142726.0  \n",
       "599998  1.0   5.0      0   124239.0  \n",
       "599999  5.0   8.0      0    84790.0  \n",
       "\n",
       "[600000 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>15634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>Expert</td>\n",
       "      <td>19477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>13623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>Master</td>\n",
       "      <td>10800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>Novice</td>\n",
       "      <td>22718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cold</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>17734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cold</td>\n",
       "      <td>Expert</td>\n",
       "      <td>22956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cold</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>15464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cold</td>\n",
       "      <td>Master</td>\n",
       "      <td>12364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cold</td>\n",
       "      <td>Novice</td>\n",
       "      <td>26271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Freezing</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>26082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Freezing</td>\n",
       "      <td>Expert</td>\n",
       "      <td>33249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Freezing</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>22818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Freezing</td>\n",
       "      <td>Master</td>\n",
       "      <td>18035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Freezing</td>\n",
       "      <td>Novice</td>\n",
       "      <td>38233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hot</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>12428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hot</td>\n",
       "      <td>Expert</td>\n",
       "      <td>15792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hot</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>10805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hot</td>\n",
       "      <td>Master</td>\n",
       "      <td>8594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hot</td>\n",
       "      <td>Novice</td>\n",
       "      <td>17850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>11919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>Expert</td>\n",
       "      <td>15078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>10363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>Master</td>\n",
       "      <td>8209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>Novice</td>\n",
       "      <td>17373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Warm</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>22774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Warm</td>\n",
       "      <td>Expert</td>\n",
       "      <td>28900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Warm</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>19899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Warm</td>\n",
       "      <td>Master</td>\n",
       "      <td>15734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Warm</td>\n",
       "      <td>Novice</td>\n",
       "      <td>33263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ord_2        ord_1  count\n",
       "0   Boiling Hot  Contributor  15634\n",
       "1   Boiling Hot       Expert  19477\n",
       "2   Boiling Hot  Grandmaster  13623\n",
       "3   Boiling Hot       Master  10800\n",
       "4   Boiling Hot       Novice  22718\n",
       "5          Cold  Contributor  17734\n",
       "6          Cold       Expert  22956\n",
       "7          Cold  Grandmaster  15464\n",
       "8          Cold       Master  12364\n",
       "9          Cold       Novice  26271\n",
       "10     Freezing  Contributor  26082\n",
       "11     Freezing       Expert  33249\n",
       "12     Freezing  Grandmaster  22818\n",
       "13     Freezing       Master  18035\n",
       "14     Freezing       Novice  38233\n",
       "15          Hot  Contributor  12428\n",
       "16          Hot       Expert  15792\n",
       "17          Hot  Grandmaster  10805\n",
       "18          Hot       Master   8594\n",
       "19          Hot       Novice  17850\n",
       "20     Lava Hot  Contributor  11919\n",
       "21     Lava Hot       Expert  15078\n",
       "22     Lava Hot  Grandmaster  10363\n",
       "23     Lava Hot       Master   8209\n",
       "24     Lava Hot       Novice  17373\n",
       "25         Warm  Contributor  22774\n",
       "26         Warm       Expert  28900\n",
       "27         Warm  Grandmaster  19899\n",
       "28         Warm       Master  15734\n",
       "29         Warm       Novice  33263"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can add counts of all the features or can also replace them or maybe group by multiple columns \n",
    "# and their counts.\n",
    "\n",
    "# E.g counting by grouping on ord_1 and ord_2 columns\n",
    "df.groupby([\"ord_2\", \"ord_1\"])[\"id\"].count().reset_index(name=\"count\")\n",
    "# in this way you are adding new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You can also create feature from these categorical variables easily\n",
    "### Just by concatenating by _\n",
    "df[\"new_feature\"] = df.ord_1.astype(str) + \"_\" + df.ord_2.astype(str)\n",
    "\n",
    "# similarity you can combine differt features easily to create new features\n",
    "# Note that: there will be many Nan values in both the cols that are combined too "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "      <th>count_ord2</th>\n",
       "      <th>new_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>c</td>\n",
       "      <td>U</td>\n",
       "      <td>Pw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>67508.0</td>\n",
       "      <td>Contributor_Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>pE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>124239.0</td>\n",
       "      <td>Grandmaster_Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>P</td>\n",
       "      <td>eN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142726.0</td>\n",
       "      <td>nan_Freezing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>64840.0</td>\n",
       "      <td>Novice_Lava Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>C</td>\n",
       "      <td>OZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>97822.0</td>\n",
       "      <td>Grandmaster_Cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>599995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>India</td>\n",
       "      <td>...</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>GZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>142726.0</td>\n",
       "      <td>Novice_Freezing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>599996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "      <td>sf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>84790.0</td>\n",
       "      <td>Novice_Boiling Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>599997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>H</td>\n",
       "      <td>MV</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142726.0</td>\n",
       "      <td>Contributor_Freezing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>599998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Master</td>\n",
       "      <td>Warm</td>\n",
       "      <td>m</td>\n",
       "      <td>X</td>\n",
       "      <td>Ey</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>124239.0</td>\n",
       "      <td>Master_Warm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>599999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>b</td>\n",
       "      <td>O</td>\n",
       "      <td>uI</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>84790.0</td>\n",
       "      <td>Contributor_Boiling Hot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2  \\\n",
       "0            0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster   \n",
       "1            1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl   \n",
       "2            2    0.0    1.0    0.0     F     N   Red        NaN  Hamster   \n",
       "3            3    NaN    0.0    0.0     F     N   Red     Circle  Hamster   \n",
       "4            4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster   \n",
       "...        ...    ...    ...    ...   ...   ...   ...        ...      ...   \n",
       "599995  599995    0.0    1.0    0.0     T     N   Red    Polygon  Axolotl   \n",
       "599996  599996    1.0    0.0    0.0     T     Y  Blue    Polygon      Dog   \n",
       "599997  599997    0.0    0.0    0.0     F     Y   Red     Circle  Axolotl   \n",
       "599998  599998    1.0    1.0    0.0     F     Y   NaN    Polygon  Axolotl   \n",
       "599999  599999    0.0    0.0    0.0     T     N  Blue   Triangle      Dog   \n",
       "\n",
       "             nom_3  ...        ord_1        ord_2 ord_3 ord_4 ord_5  day  \\\n",
       "0           Russia  ...  Contributor          Hot     c     U    Pw  6.0   \n",
       "1              NaN  ...  Grandmaster         Warm     e     X    pE  7.0   \n",
       "2           Canada  ...          NaN     Freezing     n     P    eN  5.0   \n",
       "3          Finland  ...       Novice     Lava Hot     a     C   NaN  3.0   \n",
       "4       Costa Rica  ...  Grandmaster         Cold     h     C    OZ  5.0   \n",
       "...            ...  ...          ...          ...   ...   ...   ...  ...   \n",
       "599995       India  ...       Novice     Freezing     a     R    GZ  5.0   \n",
       "599996  Costa Rica  ...       Novice  Boiling Hot     n     N    sf  NaN   \n",
       "599997      Russia  ...  Contributor     Freezing     n     H    MV  7.0   \n",
       "599998         NaN  ...       Master         Warm     m     X    Ey  1.0   \n",
       "599999      Russia  ...  Contributor  Boiling Hot     b     O    uI  5.0   \n",
       "\n",
       "        month target count_ord2              new_feature  \n",
       "0         3.0      0    67508.0          Contributor_Hot  \n",
       "1         7.0      0   124239.0         Grandmaster_Warm  \n",
       "2         9.0      0   142726.0             nan_Freezing  \n",
       "3         3.0      0    64840.0          Novice_Lava Hot  \n",
       "4        12.0      0    97822.0         Grandmaster_Cold  \n",
       "...       ...    ...        ...                      ...  \n",
       "599995    NaN      0   142726.0          Novice_Freezing  \n",
       "599996    3.0      0    84790.0       Novice_Boiling Hot  \n",
       "599997    5.0      0   142726.0     Contributor_Freezing  \n",
       "599998    5.0      0   124239.0              Master_Warm  \n",
       "599999    8.0      0    84790.0  Contributor_Boiling Hot  \n",
       "\n",
       "[600000 rows x 27 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw, we can create new features easily, but which categories to combine is still different question to answer although we can try different combinations and see which performs better for now. (Anyways we will see feature engineering later ;) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### So What do when you get categorical variables.. Do the following ;) \n",
    "\n",
    "* fill the  NaN values (Very important)\n",
    "* Convert them to integers by applying label encoding using LabelEncoder(by sklearn) or by using maping dictionary.\n",
    "* Create one-hot encoding, (skip binarization as sparse one-hot-encoding consumes less memory)\n",
    "* Go to Modelling ;) Boom :p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Lets see how to handle Nan data in categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now if you do not handle `Nan` values in the training data then if you see `Nan` values in test/real data then you will face errors (as you would be use same pre-processing for training and test/real data.\n",
    "\n",
    "* One Simple way to **handle Nan values** would be to drop them, this can work also, but what if you have lot of **Nan values** in your train set? Then you must end with less examples in train set as you have already drop **Nan values** . \n",
    "\n",
    "* Another way to **handle Nan values** is to treat them as a copmletely new category e.g. called as `\"Rare\"`. In this way, you are using all of the data as sometimes **Nan values** might contain useful info. \n",
    "\n",
    "Lets explore same categorical column and check whether it has any **any Nan values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing       142726\n",
      "Warm           124239\n",
      "Cold            97822\n",
      "Boiling Hot     84790\n",
      "Hot             67508\n",
      "Lava Hot        64840\n",
      "Name: ord_2, dtype: int64\n",
      "\n",
      "***** add flag dropna = False ** \n",
      "\n",
      "Freezing       142726\n",
      "Warm           124239\n",
      "Cold            97822\n",
      "Boiling Hot     84790\n",
      "Hot             67508\n",
      "Lava Hot        64840\n",
      "NaN             18075\n",
      "Name: ord_2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# this does not list Nan values by defauly\n",
    "print(df.ord_2.value_counts())\n",
    "print()\n",
    "print(\"***** add flag dropna = False ** \\n\")\n",
    "print(df.ord_2.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "NONE            18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fill the NaN values\n",
    "df.ord_2.fillna(\"NONE\").value_counts()\n",
    "# you can see we have lot of NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you see, we have assigned new category to the `NaN` values in this way we are using all the information of that particular feature. This may also increase the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Handle Unknown Category of one Feature?\n",
    "\n",
    "Lets say, you have new category in one of features on live data .  Consider example of `ord_2` feature, what if in your real time data, you get new category e.g. `warmer`, how you are going to tackle this? I mean this category was not present in your train dataset. \n",
    "\n",
    "One possible solution would be include new category in your train data i.e. `unknown/rare category`. Lets say we renamed `NONE` as `unknown category` , then whenever any new category comes during our live data, we can directly consider that category as `unknown category`. \n",
    "\n",
    "\n",
    "This analogy is very similar to NLP problem, where we always build a model based on a fixed vocabulary(or vocab. present in our training data). Increasing the size of the vocab. increases size of the model. E.g Transformer models like BERT are trained on `~30000 words` (for English). So, when we have a new word coming in, we mark it as **UNK** (unknown)\n",
    "\n",
    "\n",
    "So, you can either assume that your test data will have the same categories as training or you can introduce a rare or unknown category to training to take care of the new categories in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Explore another feature to another unknown category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['U', 'X', 'P', 'C', 'Q', 'R', 'Y', 'N', 'I', 'O', 'M', 'E', 'V',\n",
       "       'K', 'G', 'B', 'H', 'NONE', 'T', 'W', 'A', 'F', 'D', 'S', 'J', 'L',\n",
       "       'Z'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check no. of unique categories\n",
    "df.ord_4.fillna(\"NONE\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "G        3404\n",
       "V        3107\n",
       "J        1950\n",
       "L        1657\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check count of each category\n",
    "df.ord_4.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here we have few categories that occurs less than 4000 times and couple of categories has frequency of 2000 times. Now based on threshold we can include those categories into \"rare\" categories. \n",
    "\n",
    "To do this, its just one liner pandas function ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.ord_4 = df.ord_4.fillna(\"NONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.value_counts()[df[\"ord_4\"]].values < 2000\n",
    "# df.loc[df.ord_4.value_counts()[df[\"ord_4\"].values() < 2000], \"ord_4\"] = \"RARE\"\n",
    "# df.ord_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.loc[df[\"ord_4\"].value_counts()[df[\"ord_4\"]].values < 2000, \"ord_4\"] = \"RARE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "RARE     3607\n",
       "G        3404\n",
       "V        3107\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have assigned new category i.e. \"RARE\" to categories whose frequency is less than some threshold i.e. 2000 (here) . Now when in our real data, if we observe any type of category occurring under this feature, we would be handle that easily based on its count.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Its time to put things together and start model training ;) \n",
    "\n",
    "\n",
    "NotE: all training code is written in python scripts ;) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General pandas comments\n",
    "\n",
    "### value_counts vs count\n",
    "\n",
    "count is applied on dataframe and it does not consider nan values. mostly used on counting for groups\n",
    "\n",
    "value_counts is applied on series df (e,g single column) (does not consider nan values by default.  however there is flag, that can be passed)\n",
    "\n",
    "### Groupby\n",
    "\n",
    "Any groupby operation involves one of the following operations on the original object. They are −\n",
    "\n",
    "* Splitting the Object\n",
    "\n",
    "* Applying a function\n",
    "\n",
    "* Combining the results\n",
    "\n",
    "\n",
    "In many situations, we split the data into sets and we apply some functionality on each subset. In the apply functionality, we can perform the following operations −\n",
    "\n",
    "* Aggregation − computing a summary statistic\n",
    "\n",
    "* Transformation − perform some group-specific operation\n",
    "\n",
    "* Filtration − discarding the data with some condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby([\"target\"])[\"id\"].count().plot.bar()\n",
    "# df.target.value_counts().plot.bar()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "kaggle-comp",
   "language": "python",
   "name": "kaggle-comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
