{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.9 64-bit",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1ce46aa92e8ca635c4445555e7c358892d06f5078f3c489b2dc20b9dc0b5198f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Features with Very Low Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"dummy data\"\n",
    "var_thresh = VarianceThreshold(threshold=0.1)# remove features with variance less than 0.1\n",
    "# \n",
    "transformed_data = var_thresh.fit_transform(data)\n",
    "# transformed data will have all columns with variance less than 0.1 removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Features with High Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /home/ramesh/scikit_learn_data\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\nMedInc       1.000000 -0.119034  0.326895  -0.062040    0.004834  0.018766   \nHouseAge    -0.119034  1.000000 -0.153277  -0.077747   -0.296244  0.013191   \nAveRooms     0.326895 -0.153277  1.000000   0.847621   -0.072213 -0.004852   \nAveBedrms   -0.062040 -0.077747  0.847621   1.000000   -0.066197 -0.006181   \nPopulation   0.004834 -0.296244 -0.072213  -0.066197    1.000000  0.069863   \nAveOccup     0.018766  0.013191 -0.004852  -0.006181    0.069863  1.000000   \nLatitude    -0.079809  0.011173  0.106389   0.069721   -0.108785  0.002366   \nLongitude   -0.015176 -0.108197 -0.027540   0.013344    0.099773  0.002476   \nMedInc_Sqrt  0.984329 -0.132797  0.326688  -0.066910    0.018415  0.015266   \n\n             Latitude  Longitude  MedInc_Sqrt  \nMedInc      -0.079809  -0.015176     0.984329  \nHouseAge     0.011173  -0.108197    -0.132797  \nAveRooms     0.106389  -0.027540     0.326688  \nAveBedrms    0.069721   0.013344    -0.066910  \nPopulation  -0.108785   0.099773     0.018415  \nAveOccup     0.002366   0.002476     0.015266  \nLatitude     1.000000  -0.924664    -0.084303  \nLongitude   -0.924664   1.000000    -0.015569  \nMedInc_Sqrt -0.084303  -0.015569     1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>MedInc_Sqrt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MedInc</th>\n      <td>1.000000</td>\n      <td>-0.119034</td>\n      <td>0.326895</td>\n      <td>-0.062040</td>\n      <td>0.004834</td>\n      <td>0.018766</td>\n      <td>-0.079809</td>\n      <td>-0.015176</td>\n      <td>0.984329</td>\n    </tr>\n    <tr>\n      <th>HouseAge</th>\n      <td>-0.119034</td>\n      <td>1.000000</td>\n      <td>-0.153277</td>\n      <td>-0.077747</td>\n      <td>-0.296244</td>\n      <td>0.013191</td>\n      <td>0.011173</td>\n      <td>-0.108197</td>\n      <td>-0.132797</td>\n    </tr>\n    <tr>\n      <th>AveRooms</th>\n      <td>0.326895</td>\n      <td>-0.153277</td>\n      <td>1.000000</td>\n      <td>0.847621</td>\n      <td>-0.072213</td>\n      <td>-0.004852</td>\n      <td>0.106389</td>\n      <td>-0.027540</td>\n      <td>0.326688</td>\n    </tr>\n    <tr>\n      <th>AveBedrms</th>\n      <td>-0.062040</td>\n      <td>-0.077747</td>\n      <td>0.847621</td>\n      <td>1.000000</td>\n      <td>-0.066197</td>\n      <td>-0.006181</td>\n      <td>0.069721</td>\n      <td>0.013344</td>\n      <td>-0.066910</td>\n    </tr>\n    <tr>\n      <th>Population</th>\n      <td>0.004834</td>\n      <td>-0.296244</td>\n      <td>-0.072213</td>\n      <td>-0.066197</td>\n      <td>1.000000</td>\n      <td>0.069863</td>\n      <td>-0.108785</td>\n      <td>0.099773</td>\n      <td>0.018415</td>\n    </tr>\n    <tr>\n      <th>AveOccup</th>\n      <td>0.018766</td>\n      <td>0.013191</td>\n      <td>-0.004852</td>\n      <td>-0.006181</td>\n      <td>0.069863</td>\n      <td>1.000000</td>\n      <td>0.002366</td>\n      <td>0.002476</td>\n      <td>0.015266</td>\n    </tr>\n    <tr>\n      <th>Latitude</th>\n      <td>-0.079809</td>\n      <td>0.011173</td>\n      <td>0.106389</td>\n      <td>0.069721</td>\n      <td>-0.108785</td>\n      <td>0.002366</td>\n      <td>1.000000</td>\n      <td>-0.924664</td>\n      <td>-0.084303</td>\n    </tr>\n    <tr>\n      <th>Longitude</th>\n      <td>-0.015176</td>\n      <td>-0.108197</td>\n      <td>-0.027540</td>\n      <td>0.013344</td>\n      <td>0.099773</td>\n      <td>0.002476</td>\n      <td>-0.924664</td>\n      <td>1.000000</td>\n      <td>-0.015569</td>\n    </tr>\n    <tr>\n      <th>MedInc_Sqrt</th>\n      <td>0.984329</td>\n      <td>-0.132797</td>\n      <td>0.326688</td>\n      <td>-0.066910</td>\n      <td>0.018415</td>\n      <td>0.015266</td>\n      <td>-0.084303</td>\n      <td>-0.015569</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# fetch a regression dataset\n",
    "data = fetch_california_housing()\n",
    "x = data[\"data\"]\n",
    "col_names = data[\"feature_names\"]\n",
    "y = data[\"target\"]\n",
    "\n",
    "# convert to pandas frame\n",
    "df = pd.DataFrame(x, columns=col_names)\n",
    "# introduce a highly correlation column\n",
    "df.loc[:, \"MedInc_Sqrt\"] = df.MedInc.apply(np.sqrt)\n",
    "\n",
    "# get correlation matrix (pearson)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### we can that feature `MedInc` and `MedInc_Sqrt` have higher correlation. Thus either of them can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Feature Selection\n",
    "# It is a wrapper for univariate feature selection that you can use for almost any new problem\n",
    "\n",
    "class UnivariateFeatureSelection:\n",
    "    def __init__(self, n_features, problem_type, scoring):\n",
    "        \"\"\"\n",
    "        Custom univariate feature selection wrapper on \n",
    "        different univariate feature selection models from \n",
    "        sklearn\n",
    "\n",
    "        :param n_features: SelectPercentile if float else SelectKBest\n",
    "        :param problem_type: classif. or reg.\n",
    "        :param scoring: scoring func., string\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # for a given problem type, there are only\n",
    "        # few valid scoring methods\n",
    "        # you can extend this with your own custom\n",
    "        # methods if you wish\n",
    "        if problem_type == \"classification\":\n",
    "            valid_scoring = {\n",
    "                \"f_classif\": f_classif,\n",
    "                \"chi2\": chi2,\n",
    "                \"mutual_info_classif\": mutual_info_classif\n",
    "            }\n",
    "        else:\n",
    "            valid_scoring = {\n",
    "                \"f_regression\": f_regression,\n",
    "                \"mutual_info_regression\": mutual_info_regression\n",
    "            }\n",
    "\n",
    "        # raise exception if we do not have a valid scoring method\n",
    "        if scoring not in valid_scoring:\n",
    "            raise Exception(\"Invalid scoring function\")\n",
    "\n",
    "        # if n_features is int, we use selectkbest\n",
    "        # if n_features is float, we use selectpercentile\n",
    "        # please note that it is int in both cases in sklearn\n",
    "        if isinstance(n_features, int):\n",
    "            self.selection = SelectKBest(\n",
    "                valid_scoring[scoring],\n",
    "                k=n_features\n",
    "            )\n",
    "        elif isinstance(n_features, float):\n",
    "            self.selection = SelectPercentile(\n",
    "                valid_scoring[scoring],\n",
    "                percentile=int(n_features * 100)\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"Invalid type of feature\")\n",
    "\n",
    "    # same fit function\n",
    "    def fit(self, X, y):\n",
    "        return self.selection.fit(X,y)\n",
    "\n",
    "    # same transform function\n",
    "    def transform(self, X):\n",
    "        return self.selection.transform(X)\n",
    "\n",
    "    # same fit_transform function\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.selection.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use selectKbest\n",
    "ufs = UnivariateFeatureSelection(\n",
    "    n_features=2,\n",
    "    problem_type=\"regression\",\n",
    "    scoring=\"f_regression\"\n",
    ")\n",
    "ufs.fit(x,y)\n",
    "X_transformed = ufs.transform(x)\n",
    "\n",
    "# it choose two best features that are highly related with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[8.3252    , 6.98412698],\n       [8.3014    , 6.23813708],\n       [7.2574    , 8.28813559],\n       ...,\n       [1.7       , 5.20554273],\n       [1.8672    , 5.32951289],\n       [2.3886    , 5.25471698]])"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use `SelectPercentile` method\n",
    "ufs = UnivariateFeatureSelection(\n",
    "    n_features=0.3,\n",
    "    problem_type=\"regression\",\n",
    "    scoring=\"f_regression\"\n",
    ")\n",
    "ufs.fit(x,y)\n",
    "X_transformed = ufs.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 8.3252    ,  6.98412698, 37.88      ],\n       [ 8.3014    ,  6.23813708, 37.86      ],\n       [ 7.2574    ,  8.28813559, 37.85      ],\n       ...,\n       [ 1.7       ,  5.20554273, 39.43      ],\n       [ 1.8672    ,  5.32951289, 39.43      ],\n       [ 2.3886    ,  5.25471698, 39.37      ]])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Univariate feature selection may not always perform well. Most of the time, people prefer dong feature selection using a machine learning model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gready FeatureSelection\n"
   ]
  }
 ]
}